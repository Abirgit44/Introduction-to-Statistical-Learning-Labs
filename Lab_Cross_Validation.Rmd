---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

# Lab: Cross-Validation and the Bootstrap

## Validation set approach:

```{r}
#importing the libraries
library(ISLR)
```

```{r}
#setting the seed value
set.seed(1)
```

```{r}
#training the sample dataset
train=sample(392,196)
```

```{r}
#fitting the model
lm.fit=lm(mpg~horsepower,data=Auto,subset=train) #here we are calling the trained sample
attach(Auto) #attaching the Auto datasety
```

```{r}
#t the -train index below selects only the observations that are not in the training set
mean((mpg-predict(lm.fit,Auto))[-train]^2)
```

<!--# here we use poly() to see quadratic and cubic regression results -->

```{r}
lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset=train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
```

```{r}
lm.fit3=lm(mpg~poly(horsepower,3),data=Auto, subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
```

```{r}
#to prove that choosing diff training set results in diff errors we try the following
set.seed(2)
train=sample(392,196)
lm.fit=lm(mpg~horsepower,subset=train)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
```

```{r}
lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset=train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
```

```{r}
lm.fit3=lm(mpg~poly(horsepower,3),subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
```

## Leave-One-Out Cross-Validation

```{r}
#both glm and cv are used
glm.fit=glm(mpg~horsepower,data=Auto)
coef(glm.fit)
```

```{r}
lm.fit=lm(mpg~horsepower,data=Auto)
coef(lm.fit)
```

```{r}
library(boot) #importing for bootstraping 
```

```{r}
glm.fit=glm(mpg~horsepower,data=Auto)
cv.err=cv.glm(Auto,glm.fit) #cv stands for cross validation
cv.err$delta
```

```{r}
cv.error=rep(0,5)
for (i in 1:5){
     glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
     cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]
}
cv.error
```

<!--# Here we have found that using polynomials don't improve the model much -->

##  K Fold Cross Validation 

```{r}
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10){
  gm.fit=glm(mpg~poly(horsepower,i),data=Auto)
  cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
```

## The Bootstrap 

### Estimating the Accuracy of a Statistic of Interest

```{r}
alpha.fn=function(data,index){
  X=data$X[index]
  Y=data$Y[index]
  return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(Portfolio,1:100)
```

```{r}
set.seed(1)
alpha.fn(Portfolio,sample(100,100,replace=T))
boot(Portfolio,alpha.fn,R=1000)
```

### Estimating the Accuracy of a Linear Regression Model 

```{r}
boot.fn=function(data,index)
  return(coef(lm(mpg~horsepower,data=data,subset=index)))
```

```{r}
boot.fn(Auto,1:392)
```

```{r}
set.seed(1)
boot.fn(Auto,sample(392,392,replace=T))
```

```{r}
boot.fn(Auto,sample(392,392,replace = T))
```

```{r}
boot(Auto,boot.fn,1000)
```

```{r}
summary(lm(mpg~horsepower,data=Auto))$coef
```

```{r}
boot.fn=function(data,index)
  coefficients(lm(mpg~horsepower+I(horsepower^2),data=data,subset=index))
```

```{r}
set.seed(1)
boot(Auto,boot.fn,1000)
```

**summary**

```{r}
summary(lm(mpg~horsepower+I(horsepower^2),data=Auto))$coef
```

***And hereby the Lab 5 ends***
